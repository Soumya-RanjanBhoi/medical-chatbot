{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0834d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%pwd\n",
    "\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdf16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain_classic.text_splitter import  RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import PineconeHybridSearchRetriever\n",
    "from langchain_classic.schema import Document\n",
    "from src.logger import logging\n",
    "from dotenv import load_dotenv\n",
    "from src.exception import CustomException\n",
    "from typing import List\n",
    "from pinecone_text.sparse import BM25Encoder\n",
    "import sys,boto3,json\n",
    "from langchain_mistralai import MistralAIEmbeddings,ChatMistralAI\n",
    "from pinecone import Pinecone,ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb162b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(directory):\n",
    "    try:\n",
    "        pdf= DirectoryLoader(\n",
    "            directory, \n",
    "            glob='*.pdf',\n",
    "            loader_cls=PyPDFLoader\n",
    "        )\n",
    "\n",
    "        doc=pdf.load()\n",
    "        logging.info('document loaded successfully')\n",
    "        logging.info(f'total pages loaded: {len(doc)}')\n",
    "        return doc \n",
    "    except Exception as e:\n",
    "        raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=load_document(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4eeb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(files[14].metadata['page_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb19b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(files[0].metadata,'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'source' in files[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_useful_text(files:List[Document]) -> List:\n",
    "    filtered_docs=[]\n",
    "    for doc in files:\n",
    "        try:\n",
    "            if hasattr(doc,'page_content') and hasattr(doc,'metadata') and 'source' in doc.metadata and 'page_label' in doc.metadata:\n",
    "                cnt= doc.page_content\n",
    "                temp=Document(\n",
    "                    page_content=cnt,\n",
    "                    metadata={\n",
    "                        'source':doc.metadata['source'],\n",
    "                        'page_no':int(doc.metadata['page_label'])\n",
    "                    }\n",
    "                )\n",
    "                filtered_docs.append(temp)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "        \n",
    "    logging.info('Completed extraction of page_content & source')\n",
    "    logging.info(f'total document created: {len(filtered_docs)}')\n",
    "    return filtered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_docs=extract_useful_text(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e19480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(doc:List[Document]):\n",
    "    try:\n",
    "        text_splitter= RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "\n",
    "        text=text_splitter.split_documents(doc)\n",
    "        logging.info('Splitting completed')\n",
    "        logging.info(f'total chunks: {len(text)}')\n",
    "        return text\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_doc=split_text(filtered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8390e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    os.environ[\"MISTRAL_API_KEY\"] = os.environ.get('MISTERAL_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2511bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.environ.get('LANGSMITH_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01255a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get('LANGSMITH_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings.embed_query(final_doc[15].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc=Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i['name'] for i  in pc.list_indexes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"medical-chatbot\"\n",
    "\n",
    "if index_name not in [i['name'] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,\n",
    "        metric='dotproduct',\n",
    "        spec=ServerlessSpec(cloud='aws',region='us-east-1')\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2576818",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d07e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a33b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket=os.environ.get('BUCKET_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(\n",
    "    documents: List[Document],user_id: str,bucket_name: str):\n",
    "    try:\n",
    "        s3 = boto3.client(\"s3\")\n",
    "        print(\"S3 client initialized\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"S3 init failed: {e}\")\n",
    "\n",
    "    \n",
    "    valid_texts = []\n",
    "    valid_docs = []\n",
    "\n",
    "    for doc in documents:\n",
    "        if hasattr(doc, \"page_content\") and doc.page_content:\n",
    "            valid_texts.append(doc.page_content)\n",
    "            valid_docs.append(doc)\n",
    "        else:\n",
    "            print(f\"Skipping empty document: {doc.metadata.get('page_no', 'unknown')}\")\n",
    "\n",
    "    if not valid_texts:\n",
    "        raise ValueError(\"No valid document text found\")\n",
    "\n",
    "    print(f\"Extracted {len(valid_texts)} valid documents\")\n",
    "\n",
    "    embed_model = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "\n",
    "    try:\n",
    "        sample_vec = embed_model.embed_query(valid_texts[0])\n",
    "        dim = len(sample_vec)\n",
    "        print(f\"Embedding dimension: {dim}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Embedding test failed: {e}\")\n",
    "\n",
    "\n",
    "    bm25 = BM25Encoder.default()\n",
    "    bm25.fit(valid_texts)\n",
    "\n",
    "    pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "    existing_indexes = pc.list_indexes().names()\n",
    "\n",
    "    if user_id not in existing_indexes:\n",
    "        pc.create_index(\n",
    "            name=user_id,\n",
    "            dimension=dim,\n",
    "            metric=\"dotproduct\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "        )\n",
    "        print(f\"Created Pinecone index: {user_id}\")\n",
    "    else:\n",
    "        print(f\"Using existing Pinecone index: {user_id}\")\n",
    "\n",
    "    index = pc.Index(user_id)\n",
    "\n",
    "    \n",
    "    vectors = []\n",
    "    batch_size = 50\n",
    "\n",
    "    for i, doc in enumerate(valid_docs):\n",
    "        try:\n",
    "            doc_id = uuid.uuid4().hex[:16]\n",
    "            text = valid_texts[i]\n",
    "\n",
    "            source = doc.metadata.get(\"source\", \"unknown\")\n",
    "            page_no = doc.metadata.get(\"page_no\", -1)\n",
    "\n",
    "            s3.put_object(\n",
    "                Bucket=bucket_name,\n",
    "                Key=f\"{user_id}/{doc_id}.json\",\n",
    "                Body=json.dumps({\n",
    "                    \"id\": doc_id,\n",
    "                    \"text\": text,\n",
    "                    \"source\": source,\n",
    "                    \"page_no\": page_no\n",
    "                }),\n",
    "                ContentType=\"application/json\"\n",
    "            )\n",
    "\n",
    "            dense_vec = embed_model.embed_query(text)\n",
    "            sparse_vec = bm25.encode_documents([text])[0]\n",
    "\n",
    "            vectors.append({\n",
    "                \"id\": doc_id,\n",
    "                \"values\": dense_vec,\n",
    "                \"sparse_values\": sparse_vec,\n",
    "                \"metadata\": {\n",
    "                    \"text\": text,\n",
    "                    \"source\": source,\n",
    "                    \"page_no\": page_no,\n",
    "                    \"s3_uri\": f\"s3://{bucket_name}/{user_id}/{doc_id}.json\"\n",
    "                }\n",
    "            })\n",
    "\n",
    "            if len(vectors) >= batch_size:\n",
    "                index.upsert(vectors)\n",
    "                vectors.clear()\n",
    "                print(f\"Upserted batch ending at {i}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed doc {i}: {e}\")\n",
    "\n",
    "    if vectors:\n",
    "        index.upsert(vectors)\n",
    "        print(\"Final batch upserted\")\n",
    "\n",
    "    \n",
    "    retriever = PineconeHybridSearchRetriever(\n",
    "        embeddings=embed_model,\n",
    "        sparse_encoder=bm25,\n",
    "        index=index\n",
    "    )\n",
    "\n",
    "    return retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aacd16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=upload_file(final_doc,\"medical-chatbot\",bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7380c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=final_doc,\n",
    "    embedding=embeddings,\n",
    "    index_name='medical-chatbot',\n",
    "    text_key=\"text\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"fetch_k\": 20,\n",
    "        \"lambda_mult\": 0.5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917960d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=retriever.invoke(\"Acne treatment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f7054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain_core.messages  import SystemMessage,HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81efe565",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "        You are a medical question answering assistant.\n",
    "        You must answer the user’s question using ONLY the information provided in the given documents (context).\n",
    "        Do NOT use prior knowledge, assumptions, or external medical knowledge.\n",
    "\n",
    "        Rules you MUST follow:\n",
    "        1. If the answer is clearly stated in the documents, answer accurately and concisely.\n",
    "        2. If the documents do NOT contain enough information to answer the question, say:\n",
    "        \"The provided documents do not contain sufficient information to answer this question.\"\n",
    "        3. Do NOT add new medical advice, diagnoses, treatments, or recommendations that are not explicitly mentioned in the documents.\n",
    "        4. Do NOT speculate or generalize beyond the text.\n",
    "        5. If multiple documents provide relevant information, combine them logically.\n",
    "        6. Use medically precise language, but keep explanations clear and simple.\n",
    "        7. Do NOT mention document IDs, embeddings, vector stores, or retrieval mechanisms.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        User Question:\n",
    "        {question}\"\"\",\n",
    "        input_variables=['context','question'],\n",
    "        validate_template=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"You are a medical question answering assistant.\n",
    "\n",
    "Answer the user’s question using ONLY the information provided in the documents.\n",
    "Do not use external knowledge or assumptions.\n",
    "\n",
    "Style and tone rules:\n",
    "- Be friendly, natural, and conversational.\n",
    "- Answer directly. Do NOT start your response with phrases like\n",
    "  \"Based on the provided documents\",\n",
    "  \"According to the documents\",\n",
    "  or similar meta statements.\n",
    "- Write as if explaining to a patient in simple, clear language.\n",
    "- Do not mention documents, context, sources, or retrieval.\n",
    "\n",
    "Safety rules:\n",
    "1. If the documents clearly contain the answer, explain it simply and accurately.\n",
    "2. If the documents do NOT contain enough information, say:\n",
    "   \"I don’t have enough information in the provided material to answer that.\"\n",
    "3. Do not add medical advice, diagnoses, or treatments beyond what is explicitly stated.\n",
    "\n",
    "If a reference is ambiguous, prefer the most recently mentioned condition rather than asking for clarification.\n",
    "\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_req_text(query):\n",
    "    res=retriever.invoke(query)\n",
    "    req_text=[]\n",
    "    for dox in res:\n",
    "        req_text.append(dox.page_content)\n",
    "    return req_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ab851",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_text=[]\n",
    "for dox in docs:\n",
    "    req_text.append(dox.page_content)\n",
    "\n",
    "req_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=0.7,\n",
    "    max_retries=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82deca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"system\", \"{history}\"),\n",
    "    (\"human\", \"Context:\\n{context}\\n\\nQuestion:\\n{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [SystemMessage(content=template)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2508f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.memory import ConversationSummaryBufferMemory,ConversationBufferMemory\n",
    "from langchain_classic.chains import LLMChain\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfb7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=1500,\n",
    "    return_messages=True,\n",
    "    input_key=\"question\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95dea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS_URL=os.environ.get('REDIS_URL')\n",
    "REDIS_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_no=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = RedisChatMessageHistory(\n",
    "    url=REDIS_URL,\n",
    "    session_id=f\"medical_chat_user_{user_no}\"  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory1 = ConversationBufferMemory(\n",
    "    chat_memory=message_history,\n",
    "    return_messages=True,\n",
    "    input_key='question'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt1,\n",
    "    memory=memory1,\n",
    "    output_key='text'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"Your Query: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    context = extract_req_text(user_input)\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": user_input\n",
    "    })\n",
    "\n",
    "    print(\"Ai:\", response[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6370752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "r = redis.Redis.from_url(REDIS_URL, decode_responses=True)\n",
    "\n",
    "key = \"message_store:medical_chat_user_1\"\n",
    "\n",
    "messages = r.lrange(key, 0, -1)\n",
    "\n",
    "for m in messages:\n",
    "    print(json.loads(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
